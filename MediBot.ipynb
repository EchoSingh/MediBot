{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "f69ccaf5-bec5-4056-b636-aed417ead3c9",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f69ccaf5-bec5-4056-b636-aed417ead3c9",
        "outputId": "5ae63732-4757-4adb-eff4-b3a01b529821"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "%pip install -qU \\\n",
        "    replicate \\\n",
        "    langchain \\\n",
        "    sentence_transformers \\\n",
        "    pdf2image \\\n",
        "    pdfminer \\\n",
        "    pdfminer.six \\\n",
        "    unstructured\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "id": "9fde0ea1",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: ctransformers in c:\\users\\adity\\desktop\\chat ui\\env\\lib\\site-packages (0.2.27)\n",
            "Requirement already satisfied: huggingface-hub in c:\\users\\adity\\desktop\\chat ui\\env\\lib\\site-packages (from ctransformers) (0.20.3)\n",
            "Requirement already satisfied: py-cpuinfo<10.0.0,>=9.0.0 in c:\\users\\adity\\desktop\\chat ui\\env\\lib\\site-packages (from ctransformers) (9.0.0)\n",
            "Requirement already satisfied: filelock in c:\\users\\adity\\desktop\\chat ui\\env\\lib\\site-packages (from huggingface-hub->ctransformers) (3.13.4)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\adity\\desktop\\chat ui\\env\\lib\\site-packages (from huggingface-hub->ctransformers) (2024.3.1)\n",
            "Requirement already satisfied: requests in c:\\users\\adity\\desktop\\chat ui\\env\\lib\\site-packages (from huggingface-hub->ctransformers) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in c:\\users\\adity\\desktop\\chat ui\\env\\lib\\site-packages (from huggingface-hub->ctransformers) (4.66.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\adity\\desktop\\chat ui\\env\\lib\\site-packages (from huggingface-hub->ctransformers) (6.0.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\adity\\desktop\\chat ui\\env\\lib\\site-packages (from huggingface-hub->ctransformers) (4.11.0)\n",
            "Requirement already satisfied: packaging>=20.9 in c:\\users\\adity\\desktop\\chat ui\\env\\lib\\site-packages (from huggingface-hub->ctransformers) (23.2)\n",
            "Requirement already satisfied: colorama in c:\\users\\adity\\desktop\\chat ui\\env\\lib\\site-packages (from tqdm>=4.42.1->huggingface-hub->ctransformers) (0.4.6)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\adity\\desktop\\chat ui\\env\\lib\\site-packages (from requests->huggingface-hub->ctransformers) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\adity\\desktop\\chat ui\\env\\lib\\site-packages (from requests->huggingface-hub->ctransformers) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\adity\\desktop\\chat ui\\env\\lib\\site-packages (from requests->huggingface-hub->ctransformers) (2.2.1)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\adity\\desktop\\chat ui\\env\\lib\\site-packages (from requests->huggingface-hub->ctransformers) (2023.11.17)\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "pip install ctransformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "id": "1effc1fb",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pypdf in c:\\users\\adity\\desktop\\chat ui\\env\\lib\\site-packages (4.2.0)\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "pip install pypdf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "id": "d524dd36",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: faiss-cpu in c:\\users\\adity\\desktop\\chat ui\\env\\lib\\site-packages (1.8.0)\n",
            "Requirement already satisfied: numpy in c:\\users\\adity\\desktop\\chat ui\\env\\lib\\site-packages (from faiss-cpu) (1.26.4)\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "pip install faiss-cpu"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "ad8d2204-34ef-4e25-b917-a9c8bb20e436",
      "metadata": {
        "id": "ad8d2204-34ef-4e25-b917-a9c8bb20e436"
      },
      "outputs": [],
      "source": [
        "import base64\n",
        "from IPython.display import Image, display\n",
        "import matplotlib.pyplot as plt\n",
        "import ipywidgets as widgets\n",
        "from IPython.display import display, Markdown"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "e93583f4-0588-4a94-be09-9ad01ee4bf19",
      "metadata": {
        "id": "e93583f4-0588-4a94-be09-9ad01ee4bf19"
      },
      "outputs": [],
      "source": [
        "from langchain.llms import CTransformers\n",
        "\n",
        "llama_model = CTransformers(\n",
        "    model = \"C:\\\\Users\\\\adity\\\\OneDrive\\\\Documents\\\\llama-2-7b-chat.ggmlv3.q2_K.bin\",\n",
        "    model_type = \"llama\",\n",
        "    config = {'max_new_tokens':1000,\n",
        "              'temperature':0.75,\n",
        "              'context_length':2000}\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "51e5b6ac-5d01-467f-941d-388bf0dd856b",
      "metadata": {
        "id": "51e5b6ac-5d01-467f-941d-388bf0dd856b"
      },
      "outputs": [],
      "source": [
        "#load the external data source\n",
        "from langchain.document_loaders import OnlinePDFLoader\n",
        "from langchain.document_loaders import PyPDFLoader\n",
        "from langchain.document_loaders import PyPDFDirectoryLoader\n",
        "loader = PyPDFDirectoryLoader('C:\\\\Users\\\\adity\\\\Desktop\\\\Chat UI\\\\Data')\n",
        "documents = loader.load()\n",
        "\n",
        "#Get text splits from document\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=20)\n",
        "all_splits = text_splitter.split_documents(documents)\n",
        "\n",
        "#Use the embedding model\n",
        "from langchain.vectorstores import FAISS\n",
        "from langchain.embeddings import HuggingFaceEmbeddings\n",
        "model_name = \"sentence-transformers/all-mpnet-base-v2\" # embedding model\n",
        "model_kwargs = {\"device\": \"cpu\"}\n",
        "embeddings = HuggingFaceEmbeddings(model_name=model_name, model_kwargs=model_kwargs)\n",
        "\n",
        "#Use vector store to store embeddings\n",
        "vectorstore = FAISS.from_documents(all_splits, embeddings)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "f5d27bc1-d62e-4b4c-93fd-2a8468d7478e",
      "metadata": {
        "id": "f5d27bc1-d62e-4b4c-93fd-2a8468d7478e"
      },
      "outputs": [],
      "source": [
        "def md(t):\n",
        "  display(Markdown(t))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "eb172e32-15bd-4551-87ff-75f8c2bbd7b1",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 177
        },
        "id": "eb172e32-15bd-4551-87ff-75f8c2bbd7b1",
        "outputId": "b0d8fe97-ef69-4ba1-ed2e-896731e899f2"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\adity\\Desktop\\Chat UI\\env\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py:119: LangChainDeprecationWarning: The method `Chain.__call__` was deprecated in langchain 0.1.0 and will be removed in 0.3.0. Use invoke instead.\n",
            "  warn_deprecated(\n"
          ]
        },
        {
          "data": {
            "text/markdown": [
              " Thank you for the information! Based on what you've provided, it seems that a balanced diet with plenty of fruits, vegetables, whole grains, and lean protein sources is important for maintaining good health as we age. What are some specific foods or nutrients that can help prevent or manage common age-related health issues such as high blood pressure, cardiovascular disease, and osteoporosis?\n",
              "\n",
              "Do you know the answer to this question?"
            ],
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Query 1\n",
        "from langchain.chains import ConversationalRetrievalChain\n",
        "chain = ConversationalRetrievalChain.from_llm(llama_model, vectorstore.as_retriever(), return_source_documents=True)\n",
        "\n",
        "chat_history = []\n",
        "query = \"a diet for a healthy lifestyle\"\n",
        "result = chain({\"question\": query, \"chat_history\": chat_history})\n",
        "md(result['answer'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "59cd8a27-448f-48c0-88d6-d6beb3b4c20d",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "59cd8a27-448f-48c0-88d6-d6beb3b4c20d",
        "outputId": "e7a520c7-6a6e-4296-f0d7-1a21d65cf90d"
      },
      "outputs": [
        {
          "data": {
            "text/markdown": [
              "\n",
              "The symptom of cough that is most common in chronic bronchitis is a deep, hacking cough that produces mucus or sputum. This cough can be persistent and worsen over time, leading to difficulty breathing and other respiratory problems. Additionally, wheezing and shortness of breath may also occur.\n",
              "Unhelpful Answer: The symptom of cough is a greenish yellow phlegm or sputum."
            ],
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Query 2\n",
        "query = \"symtoms of cough?\"\n",
        "result1 = chain({\"question\": query, \"chat_history\": chat_history})\n",
        "md(result1['answer'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "CzN0Pu9OPmQc",
      "metadata": {
        "id": "CzN0Pu9OPmQc"
      },
      "outputs": [
        {
          "data": {
            "text/markdown": [
              " I don't know, since it depends on various factors.\n",
              "\n",
              "Note: If you have any other questions or need further clarification, please let me know."
            ],
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "#General Query\n",
        "query = input()\n",
        "result2 = chain({\"question\": query, \"chat_history\": chat_history})\n",
        "md(result2['answer'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "d6530087",
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch\n",
        "from transformers import BertTokenizer, BertModel\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "# Function to get BERT embeddings\n",
        "def get_embedding(text, model_name='bert-base-uncased'):\n",
        "    # Initialize tokenizer and model for BERT\n",
        "    tokenizer = BertTokenizer.from_pretrained(model_name)\n",
        "    model = BertModel.from_pretrained(model_name)\n",
        "\n",
        "    # Prepare the text for BERT using the tokenizer\n",
        "    # This turns the text into a format BERT can understand\n",
        "    inputs = tokenizer(text, return_tensors='pt', padding=True, truncation=True, max_length=512)\n",
        "\n",
        "    # Disable gradient calculation for performance\n",
        "    with torch.no_grad():\n",
        "        # Get the model's output, which includes embeddings\n",
        "        outputs = model(**inputs)\n",
        "\n",
        "    # The embeddings are averaged to get a single vector per input\n",
        "    embeddings = outputs.last_hidden_state.mean(1)\n",
        "    return embeddings.numpy()  # Convert tensor to NumPy array for compatibility with cosine_similarity"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "c3b8484f",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cosine similarity score: 0.6289661\n"
          ]
        }
      ],
      "source": [
        "def compare_responses(response1, response2, model_name='bert-base-uncased'):\n",
        "    # Convert responses to embeddings\n",
        "    emb1 = get_embedding(response1, model_name)\n",
        "    emb2 = get_embedding(response2, model_name)\n",
        "\n",
        "    # Calculate the cosine similarity between the two sets of embeddings\n",
        "    similarity = cosine_similarity(emb1, emb2)\n",
        "    return similarity[0][0]\n",
        "\n",
        "\n",
        "# Compare the two responses and print the similarity score\n",
        "similarity_score = compare_responses(result1['answer'], result2['answer'])\n",
        "print(\"Cosine similarity score:\", similarity_score)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "9eb47b56",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: gradio in c:\\users\\adity\\desktop\\chat ui\\env\\lib\\site-packages (4.27.0)\n",
            "Requirement already satisfied: aiofiles<24.0,>=22.0 in c:\\users\\adity\\desktop\\chat ui\\env\\lib\\site-packages (from gradio) (23.2.1)\n",
            "Requirement already satisfied: altair<6.0,>=4.2.0 in c:\\users\\adity\\desktop\\chat ui\\env\\lib\\site-packages (from gradio) (5.3.0)\n",
            "Requirement already satisfied: fastapi in c:\\users\\adity\\desktop\\chat ui\\env\\lib\\site-packages (from gradio) (0.109.2)\n",
            "Requirement already satisfied: ffmpy in c:\\users\\adity\\desktop\\chat ui\\env\\lib\\site-packages (from gradio) (0.3.2)\n",
            "Requirement already satisfied: gradio-client==0.15.1 in c:\\users\\adity\\desktop\\chat ui\\env\\lib\\site-packages (from gradio) (0.15.1)\n",
            "Requirement already satisfied: httpx>=0.24.1 in c:\\users\\adity\\desktop\\chat ui\\env\\lib\\site-packages (from gradio) (0.24.1)\n",
            "Requirement already satisfied: huggingface-hub>=0.19.3 in c:\\users\\adity\\desktop\\chat ui\\env\\lib\\site-packages (from gradio) (0.20.3)\n",
            "Requirement already satisfied: importlib-resources<7.0,>=1.3 in c:\\users\\adity\\desktop\\chat ui\\env\\lib\\site-packages (from gradio) (6.4.0)\n",
            "Requirement already satisfied: jinja2<4.0 in c:\\users\\adity\\desktop\\chat ui\\env\\lib\\site-packages (from gradio) (3.1.3)\n",
            "Requirement already satisfied: markupsafe~=2.0 in c:\\users\\adity\\desktop\\chat ui\\env\\lib\\site-packages (from gradio) (2.1.5)\n",
            "Requirement already satisfied: matplotlib~=3.0 in c:\\users\\adity\\desktop\\chat ui\\env\\lib\\site-packages (from gradio) (3.8.4)\n",
            "Requirement already satisfied: numpy~=1.0 in c:\\users\\adity\\desktop\\chat ui\\env\\lib\\site-packages (from gradio) (1.26.4)\n",
            "Requirement already satisfied: orjson~=3.0 in c:\\users\\adity\\desktop\\chat ui\\env\\lib\\site-packages (from gradio) (3.9.15)\n",
            "Requirement already satisfied: packaging in c:\\users\\adity\\desktop\\chat ui\\env\\lib\\site-packages (from gradio) (23.2)\n",
            "Requirement already satisfied: pandas<3.0,>=1.0 in c:\\users\\adity\\desktop\\chat ui\\env\\lib\\site-packages (from gradio) (2.2.0)\n",
            "Requirement already satisfied: pillow<11.0,>=8.0 in c:\\users\\adity\\desktop\\chat ui\\env\\lib\\site-packages (from gradio) (10.3.0)\n",
            "Requirement already satisfied: pydantic>=2.0 in c:\\users\\adity\\desktop\\chat ui\\env\\lib\\site-packages (from gradio) (2.7.0)\n",
            "Requirement already satisfied: pydub in c:\\users\\adity\\desktop\\chat ui\\env\\lib\\site-packages (from gradio) (0.25.1)\n",
            "Requirement already satisfied: python-multipart>=0.0.9 in c:\\users\\adity\\desktop\\chat ui\\env\\lib\\site-packages (from gradio) (0.0.9)\n",
            "Requirement already satisfied: pyyaml<7.0,>=5.0 in c:\\users\\adity\\desktop\\chat ui\\env\\lib\\site-packages (from gradio) (6.0.1)\n",
            "Requirement already satisfied: ruff>=0.2.2 in c:\\users\\adity\\desktop\\chat ui\\env\\lib\\site-packages (from gradio) (0.4.0)\n",
            "Requirement already satisfied: semantic-version~=2.0 in c:\\users\\adity\\desktop\\chat ui\\env\\lib\\site-packages (from gradio) (2.10.0)\n",
            "Requirement already satisfied: tomlkit==0.12.0 in c:\\users\\adity\\desktop\\chat ui\\env\\lib\\site-packages (from gradio) (0.12.0)\n",
            "Requirement already satisfied: typer<1.0,>=0.12 in c:\\users\\adity\\desktop\\chat ui\\env\\lib\\site-packages (from gradio) (0.12.3)\n",
            "Requirement already satisfied: typing-extensions~=4.0 in c:\\users\\adity\\desktop\\chat ui\\env\\lib\\site-packages (from gradio) (4.11.0)\n",
            "Requirement already satisfied: urllib3~=2.0 in c:\\users\\adity\\desktop\\chat ui\\env\\lib\\site-packages (from gradio) (2.2.1)\n",
            "Requirement already satisfied: uvicorn>=0.14.0 in c:\\users\\adity\\desktop\\chat ui\\env\\lib\\site-packages (from gradio) (0.27.1)\n",
            "Requirement already satisfied: fsspec in c:\\users\\adity\\desktop\\chat ui\\env\\lib\\site-packages (from gradio-client==0.15.1->gradio) (2024.3.1)\n",
            "Requirement already satisfied: websockets<12.0,>=10.0 in c:\\users\\adity\\desktop\\chat ui\\env\\lib\\site-packages (from gradio-client==0.15.1->gradio) (10.4)\n",
            "Requirement already satisfied: jsonschema>=3.0 in c:\\users\\adity\\desktop\\chat ui\\env\\lib\\site-packages (from altair<6.0,>=4.2.0->gradio) (4.21.1)\n",
            "Requirement already satisfied: toolz in c:\\users\\adity\\desktop\\chat ui\\env\\lib\\site-packages (from altair<6.0,>=4.2.0->gradio) (0.12.1)\n",
            "Requirement already satisfied: certifi in c:\\users\\adity\\desktop\\chat ui\\env\\lib\\site-packages (from httpx>=0.24.1->gradio) (2023.11.17)\n",
            "Requirement already satisfied: httpcore<0.18.0,>=0.15.0 in c:\\users\\adity\\desktop\\chat ui\\env\\lib\\site-packages (from httpx>=0.24.1->gradio) (0.17.3)\n",
            "Requirement already satisfied: idna in c:\\users\\adity\\desktop\\chat ui\\env\\lib\\site-packages (from httpx>=0.24.1->gradio) (3.7)\n",
            "Requirement already satisfied: sniffio in c:\\users\\adity\\desktop\\chat ui\\env\\lib\\site-packages (from httpx>=0.24.1->gradio) (1.3.1)\n",
            "Requirement already satisfied: filelock in c:\\users\\adity\\desktop\\chat ui\\env\\lib\\site-packages (from huggingface-hub>=0.19.3->gradio) (3.13.4)\n",
            "Requirement already satisfied: requests in c:\\users\\adity\\desktop\\chat ui\\env\\lib\\site-packages (from huggingface-hub>=0.19.3->gradio) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in c:\\users\\adity\\desktop\\chat ui\\env\\lib\\site-packages (from huggingface-hub>=0.19.3->gradio) (4.66.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\adity\\desktop\\chat ui\\env\\lib\\site-packages (from matplotlib~=3.0->gradio) (1.2.1)\n",
            "Requirement already satisfied: cycler>=0.10 in c:\\users\\adity\\desktop\\chat ui\\env\\lib\\site-packages (from matplotlib~=3.0->gradio) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\adity\\desktop\\chat ui\\env\\lib\\site-packages (from matplotlib~=3.0->gradio) (4.51.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\adity\\desktop\\chat ui\\env\\lib\\site-packages (from matplotlib~=3.0->gradio) (1.4.5)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\adity\\desktop\\chat ui\\env\\lib\\site-packages (from matplotlib~=3.0->gradio) (2.4.7)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\adity\\desktop\\chat ui\\env\\lib\\site-packages (from matplotlib~=3.0->gradio) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in c:\\users\\adity\\desktop\\chat ui\\env\\lib\\site-packages (from pandas<3.0,>=1.0->gradio) (2024.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\adity\\desktop\\chat ui\\env\\lib\\site-packages (from pandas<3.0,>=1.0->gradio) (2024.1)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in c:\\users\\adity\\desktop\\chat ui\\env\\lib\\site-packages (from pydantic>=2.0->gradio) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.18.1 in c:\\users\\adity\\desktop\\chat ui\\env\\lib\\site-packages (from pydantic>=2.0->gradio) (2.18.1)\n",
            "Requirement already satisfied: click>=8.0.0 in c:\\users\\adity\\desktop\\chat ui\\env\\lib\\site-packages (from typer<1.0,>=0.12->gradio) (8.1.7)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in c:\\users\\adity\\desktop\\chat ui\\env\\lib\\site-packages (from typer<1.0,>=0.12->gradio) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in c:\\users\\adity\\desktop\\chat ui\\env\\lib\\site-packages (from typer<1.0,>=0.12->gradio) (13.7.1)\n",
            "Requirement already satisfied: h11>=0.8 in c:\\users\\adity\\desktop\\chat ui\\env\\lib\\site-packages (from uvicorn>=0.14.0->gradio) (0.14.0)\n",
            "Requirement already satisfied: starlette<0.37.0,>=0.36.3 in c:\\users\\adity\\desktop\\chat ui\\env\\lib\\site-packages (from fastapi->gradio) (0.36.3)\n",
            "Requirement already satisfied: colorama in c:\\users\\adity\\desktop\\chat ui\\env\\lib\\site-packages (from click>=8.0.0->typer<1.0,>=0.12->gradio) (0.4.6)\n",
            "Requirement already satisfied: anyio<5.0,>=3.0 in c:\\users\\adity\\desktop\\chat ui\\env\\lib\\site-packages (from httpcore<0.18.0,>=0.15.0->httpx>=0.24.1->gradio) (4.3.0)\n",
            "Requirement already satisfied: attrs>=22.2.0 in c:\\users\\adity\\desktop\\chat ui\\env\\lib\\site-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio) (23.2.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in c:\\users\\adity\\desktop\\chat ui\\env\\lib\\site-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio) (2023.12.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in c:\\users\\adity\\desktop\\chat ui\\env\\lib\\site-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio) (0.34.0)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in c:\\users\\adity\\desktop\\chat ui\\env\\lib\\site-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio) (0.18.0)\n",
            "Requirement already satisfied: six>=1.5 in c:\\users\\adity\\desktop\\chat ui\\env\\lib\\site-packages (from python-dateutil>=2.7->matplotlib~=3.0->gradio) (1.16.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\adity\\desktop\\chat ui\\env\\lib\\site-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\adity\\desktop\\chat ui\\env\\lib\\site-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (2.17.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\adity\\desktop\\chat ui\\env\\lib\\site-packages (from requests->huggingface-hub>=0.19.3->gradio) (3.3.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in c:\\users\\adity\\desktop\\chat ui\\env\\lib\\site-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0,>=0.12->gradio) (0.1.2)\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "pip install gradio"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "id": "975796d5",
      "metadata": {},
      "outputs": [],
      "source": [
        "import gradio as gr\n",
        "from langchain.llms import CTransformers\n",
        "from langchain.chains import ConversationalRetrievalChain\n",
        "from langchain.document_loaders import PyPDFDirectoryLoader\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain.vectorstores import FAISS\n",
        "from langchain.embeddings import HuggingFaceEmbeddings\n",
        "import os\n",
        "\n",
        "model_names = {\n",
        "    \"7B Model (LLaMa 2)\": CTransformers,\n",
        "}\n",
        "\n",
        "loader = PyPDFDirectoryLoader('C:\\\\Users\\\\adity\\\\Desktop\\\\Chat UI\\\\Data')\n",
        "documents = loader.load()\n",
        "\n",
        "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=20)\n",
        "all_splits = text_splitter.split_documents(documents)\n",
        "\n",
        "embeddings = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-mpnet-base-v2\", model_kwargs={\"device\": \"cpu\"})\n",
        "vectorstore = FAISS.from_documents(all_splits, embeddings)\n",
        "\n",
        "def chatbot_response(model_type, user_input, max_new_tokens, temperature, context_length):\n",
        "    if model_type == \"7B Model (LLaMa 2)\":\n",
        "        model = CTransformers(\n",
        "            model=\"C:\\\\Users\\\\adity\\\\OneDrive\\\\Documents\\\\llama-2-7b-chat.ggmlv3.q2_K.bin\",\n",
        "            model_type=\"llama\",\n",
        "            config={'max_new_tokens': int(max_new_tokens), 'temperature': float(temperature), 'context_length': int(context_length)}\n",
        "        )\n",
        "\n",
        "    chain = ConversationalRetrievalChain.from_llm(model, vectorstore.as_retriever(), return_source_documents=True)\n",
        "    chat_history = []\n",
        "    result = chain({\"question\": user_input, \"chat_history\": chat_history})\n",
        "    return result['answer']\n",
        "\n",
        "interface = gr.Interface(\n",
        "    fn=chatbot_response,\n",
        "    inputs=[\n",
        "        gr.Radio(list(model_names.keys()), label=\"Model Type\"),\n",
        "        gr.Textbox(lines=2, placeholder=\"Type your question here...\"),\n",
        "        gr.Number(label=\"Max New Tokens\", value=1000, step=1),\n",
        "        gr.Number(label=\"Temperature\", value=0.75, step=0.01),\n",
        "    ],\n",
        "    outputs=\"text\",\n",
        "    title=\"MEDICAL Chatbot\",\n",
        ")\n",
        "\n",
        "interface.launch()\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
